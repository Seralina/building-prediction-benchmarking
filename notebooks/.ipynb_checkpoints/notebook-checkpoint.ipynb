{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../input/meta_open.csv\", index_col='uid', parse_dates=[\"datastart\",\"dataend\"], dayfirst=True)\n",
    "temporal = pd.read_csv(\"../input/temp_open_utc_complete.csv\", index_col='timestamp', parse_dates=True).tz_localize('utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kitkat\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# All models types\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from  sklearn.linear_model import HuberRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "    \n",
    "# Make array of models. Each model is an array of two elements.\n",
    "# First element is a model-name, second is a model itself\n",
    "models = [#['RandomForestRegressor', RandomForestRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['AdaBoostRegressor', AdaBoostRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['BaggingRegressor', BaggingRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['DecisionTreeRegressor', DecisionTreeRegressor(random_state = 42)],\n",
    "['DummyRegressor', DummyRegressor()],\n",
    "#['ExtraTreeRegressor', ExtraTreeRegressor(random_state = 42)],\n",
    "#['ExtraTreesRegressor', ExtraTreesRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['GaussianProcessRegressor', GaussianProcessRegressor(random_state = 42)],\n",
    "#['GradientBoostingRegressor', GradientBoostingRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['HuberRegressor', HuberRegressor()],\n",
    "#['KNeighborsRegressor', KNeighborsRegressor()],\n",
    "#['MLPRegressor', MLPRegressor(random_state = 42)],\n",
    "#['PassiveAggressiveRegressor', PassiveAggressiveRegressor(random_state = 42)],\n",
    "#['RANSACRegressor', RANSACRegressor(random_state = 42)],\n",
    "#['SGDRegressor', SGDRegressor(random_state = 42)],\n",
    "#['TheilSenRegressor', TheilSenRegressor(random_state = 42)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce file with metrics(MAPE, NMBE, CVRSME, RSQUARED) based on provided model\n",
    "# Results will be saved as modelName_metrics.csv\n",
    "def createMetrics(modelName, model, buildingtype):\n",
    "    buildingnames = temporal.columns[temporal.columns.str.contains(buildingtype)]\n",
    "    #print('\\n\\n' + modelName + '-' + buildingtype + '\\n_____________')\n",
    "    for singlebuilding in buildingnames[:]:\n",
    "        #print(\"Modelling: \" + singlebuilding)\n",
    "        # Get Data\n",
    "        single_timezone = meta.T[singlebuilding].timezone\n",
    "        single_start = meta.T[singlebuilding].datastart\n",
    "        single_end = meta.T[singlebuilding].dataend\n",
    "        single_building_data = pd.DataFrame(temporal[singlebuilding].tz_convert(single_timezone).truncate(before=single_start,after=single_end))\n",
    "\n",
    "        # Split into Training and Testing\n",
    "        trainingdata = single_building_data[single_building_data.index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])]\n",
    "        testdata = single_building_data[single_building_data.index.month.isin([\"4\",\"8\",\"12\"])]\n",
    "\n",
    "        # Get weather file\n",
    "        weatherfilename = meta.T[singlebuilding].newweatherfilename\n",
    "        #print(\"Weatherfile: \"+weatherfilename)\n",
    "        weather = pd.read_csv(os.path.join(\"../input/\",weatherfilename),index_col='timestamp', parse_dates=True, na_values='-9999')\n",
    "        weather = weather.tz_localize(single_timezone, ambiguous = 'infer')\n",
    "        outdoor_temp = pd.DataFrame(weather[[col for col in weather.columns if 'Temperature' in col]]).resample(\"H\").mean()\n",
    "        outdoor_temp = outdoor_temp.reindex(pd.DatetimeIndex(start=outdoor_temp.index[0], periods=len(single_building_data), freq=\"H\")).fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        # Create training data array\n",
    "        train_features = np.array(pd.concat([pd.get_dummies(trainingdata.index.hour),\n",
    "                                             pd.get_dummies(trainingdata.index.dayofweek),\n",
    "                   pd.Series(outdoor_temp[outdoor_temp.index.month.isin([\"1\",\"2\",\"3\",\"5\",\"6\",\"7\",\"9\",\"10\",\"11\"])].TemperatureC.values)], axis=1))\n",
    "        train_labels = np.array(trainingdata[singlebuilding].values)\n",
    "\n",
    "        # Create test data array\n",
    "        test_features = np.array(pd.concat([pd.get_dummies(testdata.index.hour),\n",
    "                                             pd.get_dummies(testdata.index.dayofweek),\n",
    "                   pd.Series(outdoor_temp[outdoor_temp.index.month.isin([\"4\",\"8\",\"12\"])].TemperatureC.values)], axis=1))\n",
    "        test_labels = np.array(testdata[singlebuilding].values)\n",
    "\n",
    "\n",
    "        # Train the model on training data\n",
    "        model.fit(train_features, train_labels);\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = model.predict(test_features)\n",
    "\n",
    "        # Calculate the absolute errors\n",
    "        errors = abs(predictions - test_labels)\n",
    "        # Calculate mean absolute percentage error (MAPE) and add to list\n",
    "        MAPE = 100 * np.mean((errors / test_labels))\n",
    "        NMBE = 100 * (sum(test_labels - predictions) / (pd.Series(test_labels).count() * np.mean(test_labels)))\n",
    "        CVRSME = 100 * ((sum((test_labels - predictions)**2) / (pd.Series(test_labels).count()-1))**(0.5)) / np.mean(test_labels)\n",
    "        RSQUARED = r2_score(test_labels, predictions)\n",
    "\n",
    "        #print(\"MAPE: \"+str(MAPE))\n",
    "        #print(\"NMBE: \"+str(NMBE))\n",
    "        #print(\"CVRSME: \"+str(CVRSME))\n",
    "        #print(\"R SQUARED: \"+str(RSQUARED))\n",
    "        \n",
    "        print(len(MAPE_data))\n",
    "        \n",
    "        MAPE_data[singlebuilding] = MAPE\n",
    "        NMBE_data[singlebuilding] = NMBE\n",
    "        CVRSME_data[singlebuilding] = CVRSME\n",
    "        RSQUARED_data[singlebuilding] = RSQUARED\n",
    "\n",
    "        metrics = pd.DataFrame([MAPE_data, NMBE_data, CVRSME_data, RSQUARED_data]).T\n",
    "        metrics.columns = [\"MAPE\", \"NMBE\", \"CVRSME\", \"RSQUARED\"]\n",
    "        metrics.to_csv('../results/' + modelName + '_metrics_' + buildingtype + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for elem in models:\n",
    "    # Go over all building types\n",
    "    buildingtypes = ['Office', 'PrimClass', 'UnivClass', 'UnivDorm', 'UnivLab']\n",
    "    for buildingtype in buildingtypes:\n",
    "        \n",
    "        MAPE_data = {}\n",
    "RSQUARED_data = {}\n",
    "NMBE_data = {}\n",
    "CVRSME_data = {}\n",
    "        # modelName, model, buildingtype\n",
    "        createMetrics(elem[0], elem[1], buildingtype)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
